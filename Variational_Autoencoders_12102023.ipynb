{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO8mkYbj4TQEx8krMeuRxqE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OlatundeEso/Resume/blob/main/Variational_Autoencoders_12102023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ppU0XYJ8or3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import Conv2D, Conv2DTranspose, Input, Flatten, Dense, Lambda, Reshape\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# Loading the MNIST Dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# Normalize and reshape the data\n",
        "# Normalize\n",
        "\n"
      ],
      "metadata": {
        "id": "ro2gXIZzCeZL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e522adf6-e5d3-4119-d73f-ba3510217aab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')"
      ],
      "metadata": {
        "id": "i01_1rUq6Uu1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping\n",
        "img_width = X_train.shape[1]\n",
        "img_height = X_train.shape[2]\n",
        "num_channels = 1 # MNIST ---> MNIST is Grayscale so the channel is 1\n",
        "X_train = X_train.reshape(X_train.shape[0], img_width, img_height, num_channels)\n",
        "X_test = X_test.reshape(X_test.shape[0], img_width, img_height, num_channels)\n",
        "input_shape = (img_height, img_width, num_channels)"
      ],
      "metadata": {
        "id": "mBg852XA7JNi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape # Prior to reshaping was (60000, 28, 28)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcSX0WBW8Ver",
        "outputId": "b7956eb5-8eb1-4257-b1e8-ab52fd1c2f17"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BUILD THE MODEL\n",
        "# Build the Encoder part of the model first\n",
        "# We can define 4 nos ConV2D, Flatten and then Dense"
      ],
      "metadata": {
        "id": "PRSa0McBnu78"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 2 # Number of latent dimension parameters\n",
        "input_img = Input(shape=input_shape, name = 'encoder_input')\n",
        "x = Conv2D(32, 3, padding = 'same', activation = 'relu')(input_img)\n",
        "x = Conv2D(64, 3, padding = 'same', activation = 'relu', strides=(2,2))(x)\n",
        "x = Conv2D(64, 3, padding = 'same', activation = 'relu')(x)\n",
        "x = Conv2D(64, 3, padding = 'same', activation = 'relu')(x)"
      ],
      "metadata": {
        "id": "NXYOm_-UoGpj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_shape = K.int_shape(x) # This is the shape of the Convolution layer to be provided to the decoder\n"
      ],
      "metadata": {
        "id": "ky0v6a7OpdpO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let us Flatter the output of the convolution layers"
      ],
      "metadata": {
        "id": "Y2AJw8t0pzar"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Flatten()(x)\n",
        "x = Dense(32, activation = 'relu')(x)"
      ],
      "metadata": {
        "id": "00pKvlZJp6Kx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we need to create two layers, to provide 2 outputs, one for each\n",
        "# Two outputs, for the latent mean and log variance (standard deviation)\n",
        "# We would use these to sample random variables in the latent space to which inputs are mapped"
      ],
      "metadata": {
        "id": "w4_WWG3MqL3H"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z_mu = Dense(latent_dim, name = 'latent_mu')(x) # the mean values of encoded input vectors\n",
        "z_sigma = Dense(latent_dim, name = 'latent_sigma')(x) # the std of the encoded inputs"
      ],
      "metadata": {
        "id": "xZTFElBCqp3A"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  REPARAMETERIZATION TRICK\n",
        "# We need to define the sampling function that would sample from the distribution\n",
        "# Reparameterize based on mu + sigma_squad x eps\n",
        "# This is to ensure that the gradient descent can be carried out on the network\n",
        "\n"
      ],
      "metadata": {
        "id": "DRY0ysy3rHx_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_z(args):\n",
        "  z_mu, z_sigma = args\n",
        "  eps = K.random_normal(shape= (K.shape(z_mu)[0], K.int_shape(z_mu)[1]))\n",
        "  return z_mu + K.exp(z_sigma/2) * eps"
      ],
      "metadata": {
        "id": "9RBkn3OksDzP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let us sample from the Latent Distribution space\n",
        "# z is the Lambda custom layer that we are adding for gradient descent calculations\n",
        "# using mu and sigma"
      ],
      "metadata": {
        "id": "h4tQp5K-v9Zk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = Lambda(sample_z, output_shape = (latent_dim, ), name = 'z')([z_mu, z_sigma])"
      ],
      "metadata": {
        "id": "PzauSzAowkYp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# z (the lambda layer) will be the last layer in the encoder\n",
        "# Now we should define and summarise the encoder model"
      ],
      "metadata": {
        "id": "-HUb8WPG1Sop"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dta4RLt8bcSd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Model(input_img, [z_mu, z_sigma, z], name = 'encoder')"
      ],
      "metadata": {
        "id": "zuBDC2KIbc5j"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoder.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i-Ovzql2yeg",
        "outputId": "84182a64-2ae4-4fa9-e41b-922fcb075c86"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)  [(None, 28, 28, 1)]          0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 28, 28, 32)           320       ['encoder_input[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 14, 14, 64)           18496     ['conv2d[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 14, 14, 64)           36928     ['conv2d_1[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 14, 14, 64)           36928     ['conv2d_2[0][0]']            \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 12544)                0         ['conv2d_3[0][0]']            \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 32)                   401440    ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " latent_mu (Dense)           (None, 2)                    66        ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " latent_sigma (Dense)        (None, 2)                    66        ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " z (Lambda)                  (None, 2)                    0         ['latent_mu[0][0]',           \n",
            "                                                                     'latent_sigma[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 494244 (1.89 MB)\n",
            "Trainable params: 494244 (1.89 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let us build the Decoder\n"
      ],
      "metadata": {
        "id": "9YYUtKyd28In"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recall that the Decoder takes in the Latent Distribution Vector as the Input"
      ],
      "metadata": {
        "id": "tVUZHdv-2_eu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input = Input(shape= (latent_dim, ), name = 'decoder_input')"
      ],
      "metadata": {
        "id": "oHUDSXuQ3W8I"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, we have to ensure that the we start with a shape that can be remapped\n",
        "# to the original image shape as we want our final output to be (same shape as the original input)\n",
        "# So, we add a dense layer with dimensions that can be reshaped to the desired output shape"
      ],
      "metadata": {
        "id": "Hl4KSncU4P2D"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Dense(conv_shape[1]*conv_shape[2]*conv_shape[3], activation = 'relu')(decoder_input)"
      ],
      "metadata": {
        "id": "lA-joS0o6gFX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape to the shape of the last conv layer in the encoder, so that we can upscale\n",
        "# (conv2D transpose) back to the original shape"
      ],
      "metadata": {
        "id": "od2roWXa6_oA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Reshape((conv_shape[1], conv_shape[2], conv_shape[3]))(x)"
      ],
      "metadata": {
        "id": "Ak6Hz_s57e35"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we would use  Conv2D to reverse the conv layers defined in the encoder"
      ],
      "metadata": {
        "id": "28GaWhJz7y0L"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Conv2DTranspose(32, 3, padding = 'same', activation = 'relu', strides = (2,2))(x)"
      ],
      "metadata": {
        "id": "isi8p3LW8FRs"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can add more Conv2DTranspose layers as desired\n",
        "# Now let us use Sigmoid activation"
      ],
      "metadata": {
        "id": "wsUUo47A8hjw"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Conv2DTranspose(num_channels, 3, padding = 'same', activation = 'sigmoid', name = 'decoder')(x)"
      ],
      "metadata": {
        "id": "1oK8Ua3d83I1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define and summarize the decoder model"
      ],
      "metadata": {
        "id": "jyO3VEdG-u7p"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Model(decoder_input, x, name = 'decoder-gangan')\n",
        "decoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upHEXLYW-15Q",
        "outputId": "5519cd48-1983-4a9f-d1c7-9a2d976e58be"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"decoder-gangan\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 2)]               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 12544)             37632     \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTr  (None, 28, 28, 32)        18464     \n",
            " anspose)                                                        \n",
            "                                                                 \n",
            " decoder (Conv2DTranspose)   (None, 28, 28, 1)         289       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 56385 (220.25 KB)\n",
            "Trainable params: 56385 (220.25 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we apply the decoder to the latent sample"
      ],
      "metadata": {
        "id": "_O1zqkp6BoO5"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z_decoded = decoder(z)"
      ],
      "metadata": {
        "id": "AvVtiGNYBtj4"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let us define the custome loss\n",
        "# Recall that the Variational Autoencoder is trained using 2 loss functions-\n",
        "# Reconstruction Loss and KL divergence"
      ],
      "metadata": {
        "id": "Kzm9HaxIB6ms"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us add a class to define a custom layer with loss"
      ],
      "metadata": {
        "id": "1JGCHTO0DIra"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XtXBctpioa7a"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomLayer(keras.layers.Layer):\n",
        "  def vae_loss(self, x, z_decoded):\n",
        "    x = K.flatten(x)\n",
        "    z_decoded = K.flatten(z_decoded)\n",
        "    # Calculate Reconstruction Loss\n",
        "    recon_loss = keras.metrics.binary_crossentropy(x, z_decoded)\n",
        "    # KL Divergence (Check the axis parameter below)\n",
        "    k1_loss = -5e-4 * K.mean(1 + z_sigma - K.square(z_mu) - K.exp(z_sigma), axis = -1)\n",
        "    return K.mean(recon_loss + k1_loss)\n",
        "  # Adding a Custom Loss to the Class\n",
        "  def call(self, inputs):\n",
        "    x = inputs[0]\n",
        "    z_decoded = inputs[1]\n",
        "    loss = self.vae_loss(x, z_decoded)\n",
        "    self.add_loss(loss, inputs=inputs)\n",
        "    return x"
      ],
      "metadata": {
        "id": "jXkx182-DQ_f"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o3NQazffWJwv"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Model(input_img, [z_mu, z_sigma, z], name = 'encoder')"
      ],
      "metadata": {
        "id": "fGCE1O051r50"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the custom loss to the input image and the decoded latent distribution"
      ],
      "metadata": {
        "id": "CLwBye_FKKNk"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = CustomLayer()([input_img, z_decoded])"
      ],
      "metadata": {
        "id": "HnAV2kscTDXE"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y is basically the original image after encoding img, sigma and z\n",
        "# This will be used as the output of the Variational Autoencoder."
      ],
      "metadata": {
        "id": "CZT0O8i3TQda"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae = Model(input_img, y, name ='vae')"
      ],
      "metadata": {
        "id": "ckdWAsurTnOz"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now Compile the Model"
      ],
      "metadata": {
        "id": "kc3ESNyfTvRc"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae.compile (optimizer = 'adam', loss = 'NONE')\n"
      ],
      "metadata": {
        "id": "IuieLJqFT0CF"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_guqCWOAF_a2",
        "outputId": "1fd012a8-aa61-434c-8ca7-8126e0bcca92"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vae\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)  [(None, 28, 28, 1)]          0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 28, 28, 32)           320       ['encoder_input[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 14, 14, 64)           18496     ['conv2d[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 14, 14, 64)           36928     ['conv2d_1[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 14, 14, 64)           36928     ['conv2d_2[0][0]']            \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 12544)                0         ['conv2d_3[0][0]']            \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 32)                   401440    ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " latent_mu (Dense)           (None, 2)                    66        ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " latent_sigma (Dense)        (None, 2)                    66        ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " z (Lambda)                  (None, 2)                    0         ['latent_mu[0][0]',           \n",
            "                                                                     'latent_sigma[0][0]']        \n",
            "                                                                                                  \n",
            " decoder-gangan (Functional  (None, 28, 28, 1)            56385     ['z[0][0]']                   \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " custom_layer (CustomLayer)  (None, 28, 28, 1)            0         ['encoder_input[0][0]',       \n",
            "                                                                     'decoder-gangan[0][0]']      \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 550629 (2.10 MB)\n",
            "Trainable params: 550629 (2.10 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Autoencoder"
      ],
      "metadata": {
        "id": "xYcqE2OyUnse"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae.fit(X_train, None, epochs=10, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "72CHswfLUuLQ",
        "outputId": "494d7837-df28-4a6c-916f-701b78b69f06"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-841e97f90419>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 240, in __call__\n        self.build(y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 182, in build\n        self._losses = tf.nest.map_structure(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 353, in _get_loss_object\n        loss = losses_mod.get(loss)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2929, in get\n        return deserialize(identifier, use_legacy_format=use_legacy_format)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2876, in deserialize\n        return legacy_serialization.deserialize_keras_object(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/serialization.py\", line 537, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown loss function: 'NONE'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, let us visualize the inputs mapped to the latent space\n",
        "# Remember that we have encoded inputs into the Latent Space with dimension = 2\n",
        "# Now we extract z_mu (the first parameter in the result of the encoder)"
      ],
      "metadata": {
        "id": "pNWVUN8_6OEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mu, _, _ = encoder.predict(x_test)\n",
        "# Plot dim1 and dim2 for mu\n",
        "plt.figure(figsize=(8,10))\n",
        "plt.scatter(mu[:, 0], mu[:, 1], c = y_test, cmap = 'brg')\n",
        "plt.xlabel('dim 1')\n",
        "plt.ylabel('dim 2')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3v_9eAjgmylN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let us visualize the images\n",
        "# Single decoded image with random input latent vector (of size 1 x2)\n",
        "# The Latent space range is about -5 to 5, so we would pick random values within\n",
        "# this range- we will start with -1, 1 and slowly go up to -1.5, 1.5 and see how\n",
        "# the output morphs from one image to the other"
      ],
      "metadata": {
        "id": "TOnZzz5Rsl8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_vector = np.array([[1,3]])\n",
        "decoded_example = decoder.predict(sample_vector)\n",
        "decoded_example_reshaped = decoded_example.reshape(img_width, img_height)\n",
        "plt.imshow(decoded_example_reshaped)"
      ],
      "metadata": {
        "id": "Cf_zH4uGuA6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us try to automate this process of morphing by generating multiple images\n",
        "# and plotting\n",
        "# We will use the decoder to generate images by tweaking the latent variables from the latent space\n",
        "# We would create a grid of defined size with zeros\n",
        "# We would take sample from some defined linear space, in this example [-4, 4]\n",
        "# We will feed it to the decoder and update zeros in the figure with output"
      ],
      "metadata": {
        "id": "8BF1FlSawHe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 20 # Generate 15 x 15 digits\n",
        "figure = np.zeros((img_width * n, img_height * n, num_channels))"
      ],
      "metadata": {
        "id": "9pAmIFjJ2NH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we are creating a grid of latent variables to be supplied as inputs to\n",
        "# decoder.predict()\n",
        "# We will also create vectors within the range -5 to 5 as that seems to be the range\n",
        "# in the latent space"
      ],
      "metadata": {
        "id": "AvItHiBN2xv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_x = np.linspace(-4, 4, n)\n",
        "grid_y = np.linspace(-4, 4, n)[::-1]\n"
      ],
      "metadata": {
        "id": "1VDxPUiG3itm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder for each square in the grid"
      ],
      "metadata": {
        "id": "n7b7sUXJ305Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, yi in enumerate(grid_y):\n",
        "  for j, xi in enumerate(grid_x):\n",
        "    z_sample = np.array([[xi, yi]])\n",
        "    x_decoded = decoder.predict(z_sample)\n",
        "    digit = x_decoded[0].reshape(img_width, img_height, num_channels)\n",
        "    figure[i * img_width: (i + 1) * img_width,\n",
        "           j * img_height: (j + i) * img_height] = digit\n"
      ],
      "metadata": {
        "id": "aaAqGXVi4E5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "# Reshape for Visualization\n",
        "fig_shape = np.shape(figure)\n",
        "figure = figure.reshape((fig_shape[0], fig_shape[1]))\n",
        "plt.imshow(figure, cmap = 'gnuplot2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kh7d-sYQ5qhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[20].shape"
      ],
      "metadata": {
        "id": "VUTgUNZa-an_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[20][22:23]"
      ],
      "metadata": {
        "id": "dsh7-2B1-yQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[20].shape"
      ],
      "metadata": {
        "id": "lSG-3HMAdyZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[20][:,:,0]"
      ],
      "metadata": {
        "id": "WXirkF3Vdom3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[20].shape"
      ],
      "metadata": {
        "id": "IvWhB97tgWAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(1)\n",
        "plt.subplot(221)\n",
        "plt.imshow(X_train[12][:,:,0])"
      ],
      "metadata": {
        "id": "Snl9cFr7969s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[20][22:23]"
      ],
      "metadata": {
        "id": "Jmyo-dqMAKxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[20][22:23][:, :, 0]"
      ],
      "metadata": {
        "id": "b1NGwQcZAOxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape"
      ],
      "metadata": {
        "id": "e7AsWLAy9pXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "MZjuJTor8ZOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "IkHvUc6o8gU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "TnZT8y2Z5nJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')"
      ],
      "metadata": {
        "id": "DhYyR2aO5hJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train)"
      ],
      "metadata": {
        "id": "Bpi4iB_a3hNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "w7-nLX7L3oFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.dtype"
      ],
      "metadata": {
        "id": "FCm-d80s46S1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.ndim"
      ],
      "metadata": {
        "id": "GIPqM6Sa4_j9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_one = X_train[0]\n",
        "first_one"
      ],
      "metadata": {
        "id": "K7KTDNzH33Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_one[20]/255"
      ],
      "metadata": {
        "id": "LUAGp9wE6fW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_one[26]"
      ],
      "metadata": {
        "id": "DLaYCYdo4nvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_one[26][3]"
      ],
      "metadata": {
        "id": "8_xT7H0M4w8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_one.shape"
      ],
      "metadata": {
        "id": "VQMNHNuz4d4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(first_one)"
      ],
      "metadata": {
        "id": "StFG_O_i4g_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_one"
      ],
      "metadata": {
        "id": "E5qHNrDz6IKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.size"
      ],
      "metadata": {
        "id": "tlJSd_OO3xwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train/255\n",
        "X_test = X_test/255"
      ],
      "metadata": {
        "id": "C-ZZ-E-z3YID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "Mr3IMiwplb0e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}