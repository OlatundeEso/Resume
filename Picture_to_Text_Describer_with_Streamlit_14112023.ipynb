{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OlatundeEso/Resume/blob/main/Picture_to_Text_Describer_with_Streamlit_14112023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Yh3duPEq3eVH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cca25675-2e86-48d7-80b1-2016800f70cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit --quiet\n",
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g4DyMDWn3DOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IoHDyTO63F3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "647fa74e-6768-4e27-9174-8be99beeecbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing demo.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile demo.py\n",
        "import streamlit as st\n",
        "import time\n",
        "import tempfile\n",
        "from transformers import pipeline\n",
        "def img2txt(url):\n",
        "   image_to_text = pipeline(\"image-to-text\", model = \"Salesforce/blip-image-captioning-base\")\n",
        "   text = image_to_text(url)[0]['generated_text']\n",
        "   print(text)\n",
        "   return text\n",
        "\n",
        "st.title(\"This is My Maiden Streamlit Page\")\n",
        "user_input = st.text_input(\"What is your thought about this program?\", \"All Good\")\n",
        "col1, col2 = st.columns([1, 1])\n",
        "col1.markdown(\" ### This side for my calculations\")\n",
        "col2.markdown(\" ### This side for results\")\n",
        "st.sidebar.title(\"Editor's Main Corner\")\n",
        "ml_choice = st.radio(\"Choose ML Algorithm\", [\"Linear Regression\", \"XGBoost\", \"Random Forest\"])\n",
        "if ml_choice == \"XGBoost\":\n",
        "    st.write(\"That is a nice choice - XGBoost would give you a very high accuracy\")\n",
        "# photo_capture = st.camera_input(\"Take a Photo\")\n",
        "your_cv = st.file_uploader(\"Upload Resume\", accept_multiple_files=True)\n",
        "if your_cv:\n",
        "    with st.spinner(\"File Loading\"):\n",
        "        time.sleep(5)\n",
        "        st.success(\"File Upload Successful\")\n",
        "else:\n",
        "    st.error(\"No File Uploaded Yet\")\n",
        "\n",
        "family_type = st.selectbox(\"Family Size\", (\"Monogamy\", \"Polygamy\", \"Separated\"))\n",
        "sch_choice = st.multiselect(\"Choice of Secondary School - Select as many that applies\", (\"Orimerunmun Grammar School\", \"Omo-Olorogbo Sec Sch\", \"Somori\"))\n",
        "\n",
        "# IMAGE TO TEXT TESTING\n",
        "\n",
        "pics_to_analyze = st.file_uploader(\"Upload Picture Here\")\n",
        "\n",
        "\n",
        "if pics_to_analyze is not None:\n",
        "    with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n",
        "        temp_file.write(pics_to_analyze.read())\n",
        "        # Process the temporary file\n",
        "        st.write(\"Your File is Stored temporarily on the path:\", temp_file.name)\n",
        "\n",
        "    st.markdown(\"#### This is your picture and its transcription\")\n",
        "    # st.image(pics_to_analyze)\n",
        "    st.image(pics_to_analyze, caption=\"Uploaded Image\", use_column_width=True)\n",
        "    our_text = img2txt(temp_file.name)\n",
        "    st.write(f\"The transcription of this picture is: {our_text}\")\n",
        "    # st.markdown(\"## st.write(f\"The transcription of this picture is: {our_text}\")\")\n",
        "else:\n",
        "  st.error(\"Sorry, you have either deleted or have not uploaded your picture yet\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAyPRb1m3Sd8",
        "outputId": "2446b586-cd72-43d8-f6bd-19b7e1d5abb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.73.225.25:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 5.285s\n",
            "your url is: https://major-mails-wish.loca.lt\n",
            "2023-11-18 22:03:54.635926: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-18 22:03:54.635989: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-18 22:03:54.636033: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-18 22:03:55.640104: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "config.json: 100% 4.56k/4.56k [00:00<00:00, 14.0MB/s]\n",
            "pytorch_model.bin: 100% 990M/990M [00:09<00:00, 106MB/s] \n",
            "tokenizer_config.json: 100% 506/506 [00:00<00:00, 2.37MB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 4.07MB/s]\n",
            "tokenizer.json: 100% 711k/711k [00:00<00:00, 6.29MB/s]\n",
            "special_tokens_map.json: 100% 125/125 [00:00<00:00, 529kB/s]\n",
            "preprocessor_config.json: 100% 287/287 [00:00<00:00, 1.22MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "a screenshot of a phone with the text pay\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "a woman with braid hair and a yellow jacket\n",
            "a man in a car with his shirt open\n",
            "a fire in the middle of a forest\n",
            "a man and woman dancing together in a nightclub\n"
          ]
        }
      ],
      "source": [
        "!streamlit run demo.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNr42jJnekz0q3F4Z7l86QU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}